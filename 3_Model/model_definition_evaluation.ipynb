{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Evaluation Overview\n",
    "\n",
    "This notebook provides an overview of the **Model Definition** and **Evaluation** process for a stock price prediction model using LSTM (Long Short-Term Memory) networks. The model is built, trained, and evaluated with performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Definition\n",
    "\n",
    "### Building the LSTM Model\n",
    "The function `build_lstm_model` constructs an LSTM model based on the specified hyperparameters:\n",
    "\n",
    "```python\n",
    "def build_lstm_model(window_size, num_features, best_params):\n",
    "    units = best_params['units']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    batch_size = best_params['batch_size']\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(window_size, num_features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model\n",
    "```\n",
    "\n",
    "### Training the Model\n",
    "The function `train_lstm_model` trains the LSTM model with training data and uses callbacks for early stopping and learning rate reduction:\n",
    "\n",
    "```python\n",
    "def train_lstm_model(model, x_train, y_train, epochs, batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "    return history\n",
    "```\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "The `objective` function defines the search space for hyperparameters and evaluates the model’s performance using Mean Absolute Error (MAE):\n",
    "\n",
    "```python\n",
    "def objective(trial, window_size, num_features, x_train, y_train, close_values, scaler, close_scaler, close_data):\n",
    "    units = trial.suggest_int('units', 50, 200)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(window_size, num_features)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=100, batch_size=batch_size, verbose=0, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    x_test = prepare_test_data(close_values, scaler, window_size)\n",
    "    predictions = make_predictions(model, x_test, close_scaler)\n",
    "\n",
    "    mae = calculate_mae(predictions, close_data['Close'].values[window_size:])\n",
    "    return mae\n",
    "```\n",
    "\n",
    "## 2. Model Evaluation\n",
    "\n",
    "### Preparing Test Data\n",
    "The function `prepare_test_data` scales the test data and prepares it for making predictions:\n",
    "\n",
    "```python\n",
    "def prepare_test_data(data, scaler, window_size):\n",
    "    scaled_data = scaler.transform(data)\n",
    "    x_test = [scaled_data[i-window_size:i, :] for i in range(window_size, len(scaled_data))]\n",
    "    x_test = np.array(x_test)\n",
    "    return x_test\n",
    "```\n",
    "\n",
    "### Making Predictions\n",
    "The function `make_predictions` generates predictions using the trained model and inverse-transforms them to the original scale:\n",
    "\n",
    "```python\n",
    "def make_predictions(model, x_test, close_scaler):\n",
    "    predictions = [close_scaler.inverse_transform([[model.predict(np.reshape(x_input, (1, x_input.shape[0], x_input.shape[1])))[0, 0]]])[0, 0] for x_input in x_test]\n",
    "    return np.array(predictions)\n",
    "```\n",
    "\n",
    "### Evaluating the Model\n",
    "The following functions assess the model’s performance using evaluation metrics:\n",
    "\n",
    "- **Directional Accuracy (DA)**\n",
    "  ```python\n",
    "  def calculate_da(predictions, true_values):\n",
    "      min_len = min(len(predictions), len(true_values))\n",
    "      correct_directions = sum(1 for i in range(1, min_len) if np.sign(predictions[i] - predictions[i-1]) == np.sign(true_values[i] - true_values[i-1]))\n",
    "      directional_accuracy = correct_directions / (min_len - 1)\n",
    "      return directional_accuracy\n",
    "  ```\n",
    "\n",
    "- **Mean Absolute Error (MAE)**\n",
    "  ```python\n",
    "  def calculate_mae(predictions, true_values):\n",
    "      min_len = min(len(predictions), len(true_values))\n",
    "      mae = np.mean(np.abs(predictions[:min_len] - true_values[:min_len]))\n",
    "      return mae\n",
    "  ```\n",
    "\n",
    "### Integrating and Running the Main Process\n",
    "The `main` function integrates all components, runs the training and evaluation, and prints performance metrics:\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    try:\n",
    "        ticker = input(\"Enter the stock symbol (e.g., AAPL): \").upper()\n",
    "        start_date = '2021-01-01'\n",
    "        end_date = '2024-01-01'\n",
    "        window_size = 60\n",
    "        epochs = 100\n",
    "\n",
    "        data = download_stock_data(ticker, start_date, end_date)\n",
    "        plot_close_price_history(data)\n",
    "        plot_candlestick_chart(data)\n",
    "\n",
    "        close_data = data.filter(['Close', 'Volume'])\n",
    "        close_data = add_technical_indicators(close_data)\n",
    "        close_data = close_data.dropna()\n",
    "\n",
    "        close_values = close_data.values\n",
    "        x_train, y_train, scaler, close_scaler = prepare_training_data(close_values, window_size)\n",
    "        num_features = close_values.shape[1]\n",
    "\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective(trial, window_size, num_features, x_train, y_train, close_values, scaler, close_scaler, close_data), n_trials=10)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        model = build_lstm_model(window_size, num_features, best_params)\n",
    "        history = train_lstm_model(model, x_train, y_train, epochs, best_params['batch_size'])\n",
    "\n",
    "        x_test = prepare_test_data(close_values, scaler, window_size)\n",
    "        predictions = make_predictions(model, x_test, close_scaler)\n",
    "\n",
    "        da = calculate_da(predictions, close_data['Close'].values[window_size:])\n",
    "        print(f\"Directional Accuracy (DA): {da}\")\n",
    "\n",
    "        mae = calculate_mae(predictions, close_data['Close'].values[window_size:])\n",
    "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "        print(\"Final predicted price:\", predictions[-1])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "This notebook provides a comprehensive view of the model definition and evaluation process. Use it to understand the model's construction, training, and performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
